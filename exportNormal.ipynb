{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.190 ðŸš€ Python-3.9.13 torch-2.0.1+cu118 CPU (12th Gen Intel Core(TM) i7-12800HX)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (3.3s)\n",
      "Results saved to \u001b[1m/root/modelTraining\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8n.onnx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export quantized model into onnx\n",
    "model.export(\n",
    "    simplify=True,\n",
    "    batch=1,\n",
    "    imgsz=640,\n",
    "    format=\"onnx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=yolov8n.onnx --saveEngine=yolov8n.engine\n",
      "[10/31/2023-14:38:35] [I] === Model Options ===\n",
      "[10/31/2023-14:38:35] [I] Format: ONNX\n",
      "[10/31/2023-14:38:35] [I] Model: yolov8n.onnx\n",
      "[10/31/2023-14:38:35] [I] Output:\n",
      "[10/31/2023-14:38:35] [I] === Build Options ===\n",
      "[10/31/2023-14:38:35] [I] Max batch: explicit batch\n",
      "[10/31/2023-14:38:35] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default\n",
      "[10/31/2023-14:38:35] [I] minTiming: 1\n",
      "[10/31/2023-14:38:35] [I] avgTiming: 8\n",
      "[10/31/2023-14:38:35] [I] Precision: FP32\n",
      "[10/31/2023-14:38:35] [I] LayerPrecisions: \n",
      "[10/31/2023-14:38:35] [I] Layer Device Types: \n",
      "[10/31/2023-14:38:35] [I] Calibration: \n",
      "[10/31/2023-14:38:35] [I] Refit: Disabled\n",
      "[10/31/2023-14:38:35] [I] Version Compatible: Disabled\n",
      "[10/31/2023-14:38:35] [I] TensorRT runtime: full\n",
      "[10/31/2023-14:38:35] [I] Lean DLL Path: \n",
      "[10/31/2023-14:38:35] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
      "[10/31/2023-14:38:35] [I] Exclude Lean Runtime: Disabled\n",
      "[10/31/2023-14:38:35] [I] Sparsity: Disabled\n",
      "[10/31/2023-14:38:35] [I] Safe mode: Disabled\n",
      "[10/31/2023-14:38:35] [I] Build DLA standalone loadable: Disabled\n",
      "[10/31/2023-14:38:35] [I] Allow GPU fallback for DLA: Disabled\n",
      "[10/31/2023-14:38:35] [I] DirectIO mode: Disabled\n",
      "[10/31/2023-14:38:35] [I] Restricted mode: Disabled\n",
      "[10/31/2023-14:38:35] [I] Skip inference: Disabled\n",
      "[10/31/2023-14:38:35] [I] Save engine: yolov8n.engine\n",
      "[10/31/2023-14:38:35] [I] Load engine: \n",
      "[10/31/2023-14:38:35] [I] Profiling verbosity: 0\n",
      "[10/31/2023-14:38:35] [I] Tactic sources: Using default tactic sources\n",
      "[10/31/2023-14:38:35] [I] timingCacheMode: local\n",
      "[10/31/2023-14:38:35] [I] timingCacheFile: \n",
      "[10/31/2023-14:38:35] [I] Heuristic: Disabled\n",
      "[10/31/2023-14:38:35] [I] Preview Features: Use default preview flags.\n",
      "[10/31/2023-14:38:35] [I] MaxAuxStreams: -1\n",
      "[10/31/2023-14:38:35] [I] BuilderOptimizationLevel: -1\n",
      "[10/31/2023-14:38:35] [I] Input(s)s format: fp32:CHW\n",
      "[10/31/2023-14:38:35] [I] Output(s)s format: fp32:CHW\n",
      "[10/31/2023-14:38:35] [I] Input build shapes: model\n",
      "[10/31/2023-14:38:35] [I] Input calibration shapes: model\n",
      "[10/31/2023-14:38:35] [I] === System Options ===\n",
      "[10/31/2023-14:38:35] [I] Device: 0\n",
      "[10/31/2023-14:38:35] [I] DLACore: \n",
      "[10/31/2023-14:38:35] [I] Plugins:\n",
      "[10/31/2023-14:38:35] [I] setPluginsToSerialize:\n",
      "[10/31/2023-14:38:35] [I] dynamicPlugins:\n",
      "[10/31/2023-14:38:35] [I] ignoreParsedPluginLibs: 0\n",
      "[10/31/2023-14:38:35] [I] \n",
      "[10/31/2023-14:38:35] [I] === Inference Options ===\n",
      "[10/31/2023-14:38:35] [I] Batch: Explicit\n",
      "[10/31/2023-14:38:35] [I] Input inference shapes: model\n",
      "[10/31/2023-14:38:35] [I] Iterations: 10\n",
      "[10/31/2023-14:38:35] [I] Duration: 3s (+ 200ms warm up)\n",
      "[10/31/2023-14:38:35] [I] Sleep time: 0ms\n",
      "[10/31/2023-14:38:35] [I] Idle time: 0ms\n",
      "[10/31/2023-14:38:35] [I] Inference Streams: 1\n",
      "[10/31/2023-14:38:35] [I] ExposeDMA: Disabled\n",
      "[10/31/2023-14:38:35] [I] Data transfers: Enabled\n",
      "[10/31/2023-14:38:35] [I] Spin-wait: Disabled\n",
      "[10/31/2023-14:38:35] [I] Multithreading: Disabled\n",
      "[10/31/2023-14:38:35] [I] CUDA Graph: Disabled\n",
      "[10/31/2023-14:38:35] [I] Separate profiling: Disabled\n",
      "[10/31/2023-14:38:35] [I] Time Deserialize: Disabled\n",
      "[10/31/2023-14:38:35] [I] Time Refit: Disabled\n",
      "[10/31/2023-14:38:35] [I] NVTX verbosity: 0\n",
      "[10/31/2023-14:38:35] [I] Persistent Cache Ratio: 0\n",
      "[10/31/2023-14:38:35] [I] Inputs:\n",
      "[10/31/2023-14:38:35] [I] === Reporting Options ===\n",
      "[10/31/2023-14:38:35] [I] Verbose: Disabled\n",
      "[10/31/2023-14:38:35] [I] Averages: 10 inferences\n",
      "[10/31/2023-14:38:35] [I] Percentiles: 90,95,99\n",
      "[10/31/2023-14:38:35] [I] Dump refittable layers:Disabled\n",
      "[10/31/2023-14:38:35] [I] Dump output: Disabled\n",
      "[10/31/2023-14:38:35] [I] Profile: Disabled\n",
      "[10/31/2023-14:38:35] [I] Export timing to JSON file: \n",
      "[10/31/2023-14:38:35] [I] Export output to JSON file: \n",
      "[10/31/2023-14:38:35] [I] Export profile to JSON file: \n",
      "[10/31/2023-14:38:35] [I] \n",
      "[10/31/2023-14:38:35] [I] === Device Information ===\n",
      "[10/31/2023-14:38:35] [I] Selected Device: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n",
      "[10/31/2023-14:38:35] [I] Compute Capability: 8.6\n",
      "[10/31/2023-14:38:35] [I] SMs: 58\n",
      "[10/31/2023-14:38:35] [I] Device Global Memory: 16383 MiB\n",
      "[10/31/2023-14:38:35] [I] Shared Memory per SM: 100 KiB\n",
      "[10/31/2023-14:38:35] [I] Memory Bus Width: 256 bits (ECC disabled)\n",
      "[10/31/2023-14:38:35] [I] Application Compute Clock Rate: 1.395 GHz\n",
      "[10/31/2023-14:38:35] [I] Application Memory Clock Rate: 8.001 GHz\n",
      "[10/31/2023-14:38:35] [I] \n",
      "[10/31/2023-14:38:35] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
      "[10/31/2023-14:38:35] [I] \n",
      "[10/31/2023-14:38:35] [I] TensorRT version: 8.6.1\n",
      "[10/31/2023-14:38:35] [I] Loading standard plugins\n",
      "[10/31/2023-14:38:35] [I] [TRT] [MemUsageChange] Init CUDA: CPU +383, GPU +0, now: CPU 389, GPU 1214 (MiB)\n",
      "[10/31/2023-14:38:41] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1442, GPU +266, now: CPU 1907, GPU 1480 (MiB)\n",
      "[10/31/2023-14:38:41] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
      "[10/31/2023-14:38:41] [I] Start parsing network model.\n",
      "[10/31/2023-14:38:41] [I] [TRT] ----------------------------------------------------------------\n",
      "[10/31/2023-14:38:41] [I] [TRT] Input filename:   yolov8n.onnx\n",
      "[10/31/2023-14:38:41] [I] [TRT] ONNX IR version:  0.0.8\n",
      "[10/31/2023-14:38:41] [I] [TRT] Opset version:    17\n",
      "[10/31/2023-14:38:41] [I] [TRT] Producer name:    pytorch\n",
      "[10/31/2023-14:38:41] [I] [TRT] Producer version: 2.0.1\n",
      "[10/31/2023-14:38:41] [I] [TRT] Domain:           \n",
      "[10/31/2023-14:38:41] [I] [TRT] Model version:    0\n",
      "[10/31/2023-14:38:41] [I] [TRT] Doc string:       \n",
      "[10/31/2023-14:38:41] [I] [TRT] ----------------------------------------------------------------\n",
      "[10/31/2023-14:38:41] [W] [TRT] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[10/31/2023-14:38:41] [I] Finished parsing network model. Parse time: 0.0402773\n",
      "[10/31/2023-14:38:41] [I] [TRT] Graph optimization time: 0.0191201 seconds.\n",
      "[10/31/2023-14:38:41] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[10/31/2023-14:40:02] [I] [TRT] Detected 1 inputs and 3 output network tensors.\n",
      "[10/31/2023-14:40:02] [I] [TRT] Total Host Persistent Memory: 340112\n",
      "[10/31/2023-14:40:02] [I] [TRT] Total Device Persistent Memory: 771584\n",
      "[10/31/2023-14:40:02] [I] [TRT] Total Scratch Memory: 4608\n",
      "[10/31/2023-14:40:02] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 5 MiB, GPU 261 MiB\n",
      "[10/31/2023-14:40:02] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 179 steps to complete.\n",
      "[10/31/2023-14:40:02] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 11.144ms to assign 7 blocks to 179 nodes requiring 18842112 bytes.\n",
      "[10/31/2023-14:40:02] [I] [TRT] Total Activation Memory: 18841600\n",
      "[10/31/2023-14:40:02] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +2, GPU +16, now: CPU 2, GPU 16 (MiB)\n",
      "[10/31/2023-14:40:02] [I] Engine built in 87.8532 sec.\n",
      "[10/31/2023-14:40:03] [I] [TRT] Loaded engine size: 19 MiB\n",
      "[10/31/2023-14:40:03] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +16, now: CPU 0, GPU 16 (MiB)\n",
      "[10/31/2023-14:40:03] [I] Engine deserialized in 0.0883718 sec.\n",
      "[10/31/2023-14:40:03] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +19, now: CPU 0, GPU 35 (MiB)\n",
      "[10/31/2023-14:40:03] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n",
      "[10/31/2023-14:40:03] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[10/31/2023-14:40:03] [I] Using random values for input images\n",
      "[10/31/2023-14:40:03] [I] Input binding for images with dimensions 1x3x640x640 is created.\n",
      "[10/31/2023-14:40:03] [I] Output binding for output0 with dimensions 1x84x8400 is created.\n",
      "[10/31/2023-14:40:03] [I] Starting inference\n",
      "[10/31/2023-14:40:06] [I] Warmup completed 58 queries over 200 ms\n",
      "[10/31/2023-14:40:06] [I] Timing trace has 925 queries over 3.00573 s\n",
      "[10/31/2023-14:40:06] [I] \n",
      "[10/31/2023-14:40:06] [I] === Trace details ===\n",
      "[10/31/2023-14:40:06] [I] Trace averages of 10 runs:\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.59342 ms - Host latency: 3.39484 ms (enqueue 0.984746 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.36029 ms - Host latency: 3.15091 ms (enqueue 0.929858 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.36978 ms - Host latency: 3.16952 ms (enqueue 0.907773 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.34158 ms - Host latency: 3.09687 ms (enqueue 0.873749 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.23933 ms - Host latency: 2.97453 ms (enqueue 1.11686 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.28236 ms - Host latency: 3.06362 ms (enqueue 0.999945 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.39144 ms - Host latency: 3.16686 ms (enqueue 0.926346 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.47565 ms - Host latency: 3.27575 ms (enqueue 1.05824 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.50371 ms - Host latency: 3.30773 ms (enqueue 1.14668 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.68384 ms - Host latency: 3.51162 ms (enqueue 1.18121 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.5407 ms - Host latency: 3.36638 ms (enqueue 1.02861 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.53019 ms - Host latency: 3.30158 ms (enqueue 1.19279 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.60798 ms - Host latency: 3.37698 ms (enqueue 0.956848 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.4901 ms - Host latency: 3.31451 ms (enqueue 1.12628 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.63074 ms - Host latency: 3.4616 ms (enqueue 1.15613 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.52639 ms - Host latency: 3.33375 ms (enqueue 1.00521 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.45878 ms - Host latency: 3.26096 ms (enqueue 0.973999 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.43314 ms - Host latency: 3.23119 ms (enqueue 1.0327 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.34769 ms - Host latency: 3.11191 ms (enqueue 0.902203 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.23545 ms - Host latency: 2.97764 ms (enqueue 0.845612 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.32654 ms - Host latency: 3.09604 ms (enqueue 0.983911 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.25583 ms - Host latency: 2.98472 ms (enqueue 0.820795 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.36245 ms - Host latency: 3.09934 ms (enqueue 0.958716 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.45444 ms - Host latency: 3.19783 ms (enqueue 1.05306 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.53168 ms - Host latency: 3.27498 ms (enqueue 0.929303 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.37253 ms - Host latency: 3.10952 ms (enqueue 0.964063 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.41853 ms - Host latency: 3.15967 ms (enqueue 0.982117 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.17781 ms - Host latency: 2.93434 ms (enqueue 0.998669 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.16617 ms - Host latency: 2.91226 ms (enqueue 1.0298 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.41992 ms - Host latency: 3.16407 ms (enqueue 1.003 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.3943 ms - Host latency: 3.12521 ms (enqueue 0.862854 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.38026 ms - Host latency: 3.11404 ms (enqueue 0.829517 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.34956 ms - Host latency: 3.12051 ms (enqueue 1.15105 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.3224 ms - Host latency: 3.09495 ms (enqueue 0.840967 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.17544 ms - Host latency: 2.91296 ms (enqueue 1.04324 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.13374 ms - Host latency: 2.9073 ms (enqueue 0.856763 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.33821 ms - Host latency: 3.1157 ms (enqueue 0.899353 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.23838 ms - Host latency: 3.01478 ms (enqueue 0.934875 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.20732 ms - Host latency: 2.98969 ms (enqueue 0.864124 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.16118 ms - Host latency: 2.9353 ms (enqueue 0.939551 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.15751 ms - Host latency: 2.92839 ms (enqueue 0.899084 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.18418 ms - Host latency: 2.96185 ms (enqueue 0.844629 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.16869 ms - Host latency: 2.95826 ms (enqueue 1.13646 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.18654 ms - Host latency: 2.99939 ms (enqueue 0.938171 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.37595 ms - Host latency: 3.15464 ms (enqueue 1.25349 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.37303 ms - Host latency: 3.19253 ms (enqueue 1.19121 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.72184 ms - Host latency: 3.54567 ms (enqueue 1.11306 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.84087 ms - Host latency: 3.72162 ms (enqueue 1.37067 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.99094 ms - Host latency: 3.84065 ms (enqueue 1.06979 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.67581 ms - Host latency: 3.51464 ms (enqueue 1.03146 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.74912 ms - Host latency: 3.59961 ms (enqueue 1.59875 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.51932 ms - Host latency: 3.31035 ms (enqueue 1.15927 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.74738 ms - Host latency: 3.50044 ms (enqueue 0.944299 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.65051 ms - Host latency: 3.3822 ms (enqueue 0.833765 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.7186 ms - Host latency: 3.49175 ms (enqueue 1.41101 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.72909 ms - Host latency: 3.47406 ms (enqueue 1.02114 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 3.30354 ms - Host latency: 4.03984 ms (enqueue 0.942261 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.15579 ms - Host latency: 2.90876 ms (enqueue 1.09824 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.15571 ms - Host latency: 2.90422 ms (enqueue 1.25913 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.11279 ms - Host latency: 2.85889 ms (enqueue 0.958984 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.105 ms - Host latency: 2.83914 ms (enqueue 1.128 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.13579 ms - Host latency: 2.87344 ms (enqueue 1.52859 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.1335 ms - Host latency: 2.86599 ms (enqueue 1.1011 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.1835 ms - Host latency: 2.92646 ms (enqueue 1.06206 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.17349 ms - Host latency: 2.9114 ms (enqueue 1.57217 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.15212 ms - Host latency: 2.93179 ms (enqueue 1.18381 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.19043 ms - Host latency: 2.98438 ms (enqueue 1.06611 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.24929 ms - Host latency: 3.01956 ms (enqueue 0.986182 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.59834 ms - Host latency: 3.35349 ms (enqueue 2.28474 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.64324 ms - Host latency: 3.40513 ms (enqueue 2.09978 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.28274 ms - Host latency: 3.06814 ms (enqueue 0.997681 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.42178 ms - Host latency: 3.21243 ms (enqueue 0.982153 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.31348 ms - Host latency: 3.1043 ms (enqueue 1.00911 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.32397 ms - Host latency: 3.06443 ms (enqueue 0.898242 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.26951 ms - Host latency: 3.09478 ms (enqueue 1.06968 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.37219 ms - Host latency: 3.13408 ms (enqueue 0.895386 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.40632 ms - Host latency: 3.20994 ms (enqueue 0.917676 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.40247 ms - Host latency: 3.19805 ms (enqueue 0.939526 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.31707 ms - Host latency: 3.06375 ms (enqueue 1.09348 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.39673 ms - Host latency: 3.22341 ms (enqueue 1.06221 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.58171 ms - Host latency: 3.40344 ms (enqueue 1.08442 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.62063 ms - Host latency: 3.43386 ms (enqueue 1.09873 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.4959 ms - Host latency: 3.36301 ms (enqueue 1.31697 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.53435 ms - Host latency: 3.33665 ms (enqueue 1.09324 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.51543 ms - Host latency: 3.31057 ms (enqueue 1.20181 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.32556 ms - Host latency: 3.13723 ms (enqueue 0.956812 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.34915 ms - Host latency: 3.09106 ms (enqueue 0.966919 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.23303 ms - Host latency: 3.03198 ms (enqueue 1.04326 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.16023 ms - Host latency: 2.88762 ms (enqueue 0.898975 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.18391 ms - Host latency: 2.91401 ms (enqueue 0.840918 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.18198 ms - Host latency: 2.90811 ms (enqueue 0.931152 ms)\n",
      "[10/31/2023-14:40:06] [I] Average on 10 runs - GPU latency: 2.13145 ms - Host latency: 2.88113 ms (enqueue 0.884424 ms)\n",
      "[10/31/2023-14:40:06] [I] \n",
      "[10/31/2023-14:40:06] [I] === Performance summary ===\n",
      "[10/31/2023-14:40:06] [I] Throughput: 307.746 qps\n",
      "[10/31/2023-14:40:06] [I] Latency: min = 2.73962 ms, max = 9.01489 ms, mean = 3.16798 ms, median = 3.11157 ms, percentile(90%) = 3.52673 ms, percentile(95%) = 3.63971 ms, percentile(99%) = 4.00586 ms\n",
      "[10/31/2023-14:40:06] [I] Enqueue Time: min = 0.6604 ms, max = 6.6582 ms, mean = 1.05959 ms, median = 0.951538 ms, percentile(90%) = 1.32324 ms, percentile(95%) = 1.70142 ms, percentile(99%) = 3.26294 ms\n",
      "[10/31/2023-14:40:06] [I] H2D Latency: min = 0.430664 ms, max = 0.740356 ms, mean = 0.4816 ms, median = 0.467041 ms, percentile(90%) = 0.547363 ms, percentile(95%) = 0.592529 ms, percentile(99%) = 0.644165 ms\n",
      "[10/31/2023-14:40:06] [I] GPU Compute Time: min = 2.005 ms, max = 8.27686 ms, mean = 2.39156 ms, median = 2.32959 ms, percentile(90%) = 2.72284 ms, percentile(95%) = 2.82617 ms, percentile(99%) = 3.13635 ms\n",
      "[10/31/2023-14:40:06] [I] D2H Latency: min = 0.267822 ms, max = 0.468018 ms, mean = 0.294815 ms, median = 0.284363 ms, percentile(90%) = 0.331299 ms, percentile(95%) = 0.354065 ms, percentile(99%) = 0.394775 ms\n",
      "[10/31/2023-14:40:06] [I] Total Host Walltime: 3.00573 s\n",
      "[10/31/2023-14:40:06] [I] Total GPU Compute Time: 2.21219 s\n",
      "[10/31/2023-14:40:06] [W] * GPU compute time is unstable, with coefficient of variance = 13.2219%.\n",
      "[10/31/2023-14:40:06] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
      "[10/31/2023-14:40:06] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[10/31/2023-14:40:06] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=yolov8n.onnx --saveEngine=yolov8n.engine\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=yolov8n.onnx --saveEngine=yolov8n.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
